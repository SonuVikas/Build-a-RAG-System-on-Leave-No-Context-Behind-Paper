{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc1d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/290.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/290.4 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/290.4 kB 393.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 266.2/290.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.4/290.4 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22fc6507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.45 (from langchain_community)\n",
      "  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
      "  Downloading langsmith-0.1.51-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.45->langchain_community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.45->langchain_community)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.45->langchain_community) (1.10.12)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
      "  Downloading orjson-3.10.1-cp311-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.9/50.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain_community) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.6/1.9 MB 17.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 15.4 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_core-0.1.46-py3-none-any.whl (299 kB)\n",
      "   ---------------------------------------- 0.0/299.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 299.3/299.3 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.51-py3-none-any.whl (115 kB)\n",
      "   ---------------------------------------- 0.0/116.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 116.0/116.0 kB ? eta 0:00:00\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.1-cp311-none-win_amd64.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.1/139.1 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   -------------------------------------- - 51.2/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB 910.0 kB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, packaging, orjson, jsonpatch, marshmallow, langsmith, langchain-core, dataclasses-json, langchain_community\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 langchain-core-0.1.46 langchain_community-0.0.34 langsmith-0.1.51 marshmallow-3.21.1 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ec6e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-text-splitters\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.28 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-text-splitters) (0.1.46)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (0.1.51)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (1.10.12)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (8.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (3.10.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain-text-splitters) (2024.2.2)\n",
      "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: langchain-text-splitters\n",
      "Successfully installed langchain-text-splitters-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc3839f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-1.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting google-generativeai<0.6.0,>=0.5.0 (from langchain-google-genai)\n",
      "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.27 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.1.46)\n",
      "Collecting google-ai-generativelanguage==0.6.2 (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_api_python_client-2.127.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.20.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.10.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.9.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (0.1.51)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (8.2.2)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (3.10.1)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.6)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading grpcio-1.62.2-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2024.2.2)\n",
      "Collecting protobuf (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Downloading langchain_google_genai-1.0.2-py3-none-any.whl (28 kB)\n",
      "Downloading google_generativeai-0.5.2-py3-none-any.whl (146 kB)\n",
      "   ---------------------------------------- 0.0/146.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 146.8/146.8 kB 9.1 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl (664 kB)\n",
      "   ---------------------------------------- 0.0/664.5 kB ? eta -:--:--\n",
      "   ----------------------------------- --- 604.2/664.5 kB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 664.5/664.5 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.3/138.3 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "   ---------------------------------------- 0.0/189.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 189.2/189.2 kB ? eta 0:00:00\n",
      "Downloading google_api_python_client-2.127.0-py2.py3-none-any.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.6/12.7 MB 33.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.2/12.7 MB 23.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.2/12.7 MB 25.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.1/12.7 MB 22.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.4/12.7 MB 23.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.2/12.7 MB 21.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.7 MB 20.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.7 MB 19.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.8/12.7 MB 19.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.2/12.7 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.6/12.7 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.0/12.7 MB 16.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.3/12.7 MB 16.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.8/12.7 MB 15.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.2/12.7 MB 14.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/12.7 MB 14.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.1/12.7 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.7 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.7 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.7 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.7/12.7 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 0.0/229.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 229.1/229.1 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.8/48.8 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.62.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 12.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.8/3.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.2/3.8 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.6/3.8 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.0/3.8 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 10.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.0/3.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.5/3.8 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "Successfully installed google-ai-generativelanguage-0.6.2 google-api-core-2.18.0 google-api-python-client-2.127.0 google-auth-2.29.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.2 googleapis-common-protos-1.63.0 grpcio-1.62.2 grpcio-status-1.62.2 httplib2-0.22.0 langchain-google-genai-1.0.2 proto-plus-1.23.0 protobuf-4.25.3 rsa-4.9 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7791c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf7db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = PyPDFLoader(r\"C:\\Users\\dell\\Desktop\\Internship 2024\\RAGS\\Rag 2404.07143v1.pdf\")\n",
    "pages=df.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8beaabc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 568, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "\n",
    "chunks=text_splitter.split_documents(pages)\n",
    "\n",
    "print(len(chunks))\n",
    "\n",
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e8ba4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Preprint.\\n\\nUnder review.\\n\\nLeave No Context Behind:\\nEfficient Infinite Context Transformers with Infini-attention\\nTsendsuren Munkhdalai, Manaal Faruqui and Siddharth Gopal\\nGoogle\\ntsendsuren@google.com\\nAbstract\\nThis work introduces an efficient method to scale Transformer-based Large\\nLanguage Models (LLMs) to infinitely long inputs with bounded memory\\nand computation.\\n\\nA key component in our proposed approach is a new at-\\ntention technique dubbed Infini-attention.', metadata={'source': 'C:\\\\Users\\\\dell\\\\Desktop\\\\Internship 2024\\\\RAGS\\\\Rag 2404.07143v1.pdf', 'page': 0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0609ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=\"AIzaSyDtp7Ojmc66jO3bNdYHd3L0pLNxfdLHf2I\", model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1660abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the chunks in vector store\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Embed each chunk and load it into the vector store\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db_\")\n",
    "\n",
    "# Persist the database on drive\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707b23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a Connection with the ChromaDB\n",
    "db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d405b882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "# Converting CHROMA db_connection to Retriever Object\n",
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49cfc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cddef651",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # System Message Prompt Template\n",
    "    SystemMessage(content=\"\"\"You are a Helpful AI Bot. \n",
    "    Your task is to provide assistance based on the context given by the user. \n",
    "    Make sure your answers are relevant and helpful.\"\"\"),\n",
    "    # Human Message Prompt Template\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer: \"\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35fd5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=\"AIzaSyDtp7Ojmc66jO3bNdYHd3L0pLNxfdLHf2I\", model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da907f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72ade762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1abdcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Gating Score Visualization Explained:\\n\\nBased on the context provided, **gating score visualization** refers to the graphical representation of the gating score, specifically using the sigmoid function (sigmoid(β)), for the compressive memory within each attention head and layer of the Infini-attention model. \\n\\n**Figure 3** in the context showcases this visualization, revealing valuable insights into the behavior of attention heads after training.  The visualization helps identify two distinct types of heads:\\n\\n* **Specialized Heads:** These heads exhibit gating scores close to either 0 or 1. This indicates a strong preference for utilizing either the compressed memory or the current input, demonstrating a focused role in the attention mechanism.\\n* **Mixer Heads:** In contrast, these heads display gating scores around 0.5. This suggests a more balanced approach, combining information from both the compressed memory and the current input for a blended representation.\\n\\nAnalyzing the gating score visualization allows researchers to understand the specific roles and contributions of different attention heads within the Infini-attention model, shedding light on its internal workings and effectiveness. \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"what is gating score visualization\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d52bac6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Gating Score Visualization Explained:\n",
       "\n",
       "Based on the context provided, **gating score visualization** refers to the graphical representation of the gating score, specifically using the sigmoid function (sigmoid(β)), for the compressive memory within each attention head and layer of the Infini-attention model. \n",
       "\n",
       "**Figure 3** in the context showcases this visualization, revealing valuable insights into the behavior of attention heads after training.  The visualization helps identify two distinct types of heads:\n",
       "\n",
       "* **Specialized Heads:** These heads exhibit gating scores close to either 0 or 1. This indicates a strong preference for utilizing either the compressed memory or the current input, demonstrating a focused role in the attention mechanism.\n",
       "* **Mixer Heads:** In contrast, these heads display gating scores around 0.5. This suggests a more balanced approach, combining information from both the compressed memory and the current input for a blended representation.\n",
       "\n",
       "Analyzing the gating score visualization allows researchers to understand the specific roles and contributions of different attention heads within the Infini-attention model, shedding light on its internal workings and effectiveness. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f30bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2fb8c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Memory Retrieval and Update in Compressive Memory Systems:\\n\\nBased on the context provided, it seems like you're dealing with a **compressive memory system**. Let's break down how memory retrieval and update work in this context:\\n\\n**Memory Retrieval:**\\n\\n*   **Linear Attention Mechanism:** The system uses a linear attention mechanism, similar to those found in transformer models (Shen et al., 2018). This mechanism allows the system to focus on relevant parts of the stored memory when retrieving information. \\n*   **Katharopoulos et al. (2020):** The specific retrieval mechanism employed is based on the work of Katharopoulos et al. (2020). This method was likely chosen for its simplicity and effectiveness.\\n*   **Bounded Costs:** Unlike traditional memory systems that grow with the input sequence, compressive memory maintains a fixed number of parameters. This ensures predictable storage and computational costs during retrieval.\\n\\n**Memory Update:**\\n\\n*   **Parameter Adjustment:**  New information is integrated into the memory by adjusting its existing parameters. The objective is to modify the parameters in such a way that the new information can be accurately retrieved later.\\n*   **Stable Training Techniques:**  The system leverages stable training techniques from related methods to ensure the effective incorporation of new information without compromising the stored memory.\\n\\n**Benefits of this Approach:**\\n\\n*   **Efficiency:**  Compressive memory offers efficient storage and computation compared to traditional memory systems that grow linearly with input size.\\n*   **Effectiveness:** The use of linear attention and established retrieval mechanisms like Katharopoulos et al. (2020) ensures effective retrieval of stored information.\\n\\n**Additional Considerations:**\\n\\n*   The specific details of the memory update rule and retrieval mechanism would be further explained in the referenced papers (Shen et al., 2018; Katharopoulos et al., 2020).\\n*   The effectiveness of this approach likely depends on the specific task and the nature of the information being stored and retrieved. \\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Can you please tell me about meory retival and memory update\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32ccb36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Memory Retrieval and Update in Compressive Memory Systems:\n",
       "\n",
       "Based on the context provided, it seems like you're dealing with a **compressive memory system**. Let's break down how memory retrieval and update work in this context:\n",
       "\n",
       "**Memory Retrieval:**\n",
       "\n",
       "*   **Linear Attention Mechanism:** The system uses a linear attention mechanism, similar to those found in transformer models (Shen et al., 2018). This mechanism allows the system to focus on relevant parts of the stored memory when retrieving information. \n",
       "*   **Katharopoulos et al. (2020):** The specific retrieval mechanism employed is based on the work of Katharopoulos et al. (2020). This method was likely chosen for its simplicity and effectiveness.\n",
       "*   **Bounded Costs:** Unlike traditional memory systems that grow with the input sequence, compressive memory maintains a fixed number of parameters. This ensures predictable storage and computational costs during retrieval.\n",
       "\n",
       "**Memory Update:**\n",
       "\n",
       "*   **Parameter Adjustment:**  New information is integrated into the memory by adjusting its existing parameters. The objective is to modify the parameters in such a way that the new information can be accurately retrieved later.\n",
       "*   **Stable Training Techniques:**  The system leverages stable training techniques from related methods to ensure the effective incorporation of new information without compromising the stored memory.\n",
       "\n",
       "**Benefits of this Approach:**\n",
       "\n",
       "*   **Efficiency:**  Compressive memory offers efficient storage and computation compared to traditional memory systems that grow linearly with input size.\n",
       "*   **Effectiveness:** The use of linear attention and established retrieval mechanisms like Katharopoulos et al. (2020) ensures effective retrieval of stored information.\n",
       "\n",
       "**Additional Considerations:**\n",
       "\n",
       "*   The specific details of the memory update rule and retrieval mechanism would be further explained in the referenced papers (Shen et al., 2018; Katharopoulos et al., 2020).\n",
       "*   The effectiveness of this approach likely depends on the specific task and the nature of the information being stored and retrieved. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f246d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
